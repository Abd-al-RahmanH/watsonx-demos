{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.document_loaders import PDFMinerLoader\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\", None)\n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "\n",
    "creds = {\n",
    "    \"url\"    : \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\" : api_key\n",
    "}\n",
    "\n",
    "params = {\n",
    "    GenParams.DECODING_METHOD:\"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS:500, # 150 / 200\n",
    "    GenParams.MIN_NEW_TOKENS:50, # 30 / 50\n",
    "    GenParams.REPETITION_PENALTY:1.7\n",
    "}\n",
    "\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size= chunk_size, \n",
    "                                               chunk_overlap=chunk_overlap,\n",
    "                                               separators=[\"\\n\\n\" \n",
    "                                                        #    ,\"(?=>\\.)\"\n",
    "                                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings()\n",
    "# embeddings = HuggingFaceInstructEmbeddings(\n",
    "#             model_name=\"hkunlp/instructor-large\"\n",
    "#         )\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digest the pdf to vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when your document number increase, you would like to do filtering to narrow down the search scope, and you can leverage metadata to do so, firstly, you need to tag your document with corresponding metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", None)\n",
    "MILVUS_HOST = os.getenv(\"MILVUS_HOST\", None)\n",
    "MILVUS_PORT = os.getenv(\"MILVUS_PORT\", None)\n",
    "print(COLLECTION_NAME)\n",
    "print(MILVUS_HOST)\n",
    "print(MILVUS_PORT)\n",
    "\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "connections.connect(COLLECTION_NAME, host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "try:\n",
    "    if utility.has_collection(COLLECTION_NAME):\n",
    "        utility.drop_collection(COLLECTION_NAME)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ModelTypes.MT0_XXL,creds,params,project_id)\n",
    "llm = WatsonxLLM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"category.txt\", \"r\")\n",
    "categories = file.readlines()\n",
    "\n",
    "print(len(categories))\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "docs = []\n",
    "\n",
    "for category in categories:\n",
    "    for path in Path('../../menu/'+category).rglob('*.pdf'):\n",
    "        loader = PDFMinerLoader('../../menu/'+category+'/'+ path.name)\n",
    "        data = loader.load()\n",
    "        for doc in data:\n",
    "            doc.metadata['product'] = category\n",
    "        docs += text_splitter.split_documents(data)\n",
    "\n",
    "# prompt_template = \"Summerize the message \\\"{content}\\\"\"\n",
    "\n",
    "# llm_chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt=PromptTemplate.from_template(prompt_template)\n",
    "# )\n",
    "\n",
    "db = Milvus.from_documents(docs,embeddings,\n",
    "                        collection_name = COLLECTION_NAME,\n",
    "                        connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query the vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", None)\n",
    "MILVUS_HOST = os.getenv(\"MILVUS_HOST\", None)\n",
    "MILVUS_PORT = os.getenv(\"MILVUS_PORT\", None)\n",
    "print(COLLECTION_NAME)\n",
    "print(MILVUS_HOST)\n",
    "print(MILVUS_PORT)\n",
    "db = Milvus(\n",
    "    embedding_function = embeddings,\n",
    "    collection_name = COLLECTION_NAME,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT},\n",
    "    drop_old = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"sample.txt\", \"r\")\n",
    "questions = file.readlines()\n",
    "\n",
    "print(len(questions))\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can do filtering on similarity_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "{context}\n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=db.as_retriever(search_kwargs={'k': 3}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "# result = qa_chain1({\"query\": \"how to clean the refregirator?\"})\n",
    "# result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "questions = [\n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] There's noise after installation. Is this normal?\n",
    "[Agent] What product is it?\n",
    "[Customer] Dryer\n",
    "Query: Is it normal for my dryer to make a lot of noise after installation?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] It seems my clothes aren't drying properly.\n",
    "[Agent] What product are you using?\n",
    "[Customer] Dryer\n",
    "Query: What can I do if my clothes aren't drying properly?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] The washing machine isn't working. How can I fix it?\n",
    "[Agent] Can you elaborate so that I can help with troubleshooting?\n",
    "[Customer] After each wash cycle, I find that the load is still wet.\n",
    "Query: How can I fix my washing machine? I have a Samsung washer.\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] How can I set the water temperature?\n",
    "[Agent] Can you provide the product you are using?\n",
    "[Customer] Washing Machine\n",
    "Query: How can I set the water temperature? on the washing machine?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] My step count isn't accurate when I run.\n",
    "[Agent] What is the product you are using?\n",
    "[Customer] Galaxy watch6\n",
    "Query: How do I get my step count to be accurate when I run? I have a Samsung Galaxy watch6.\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] The watch vibration feels too strong.\n",
    "[Agent] Can you provide the product?\n",
    "[Customer] Galaxy watch6\n",
    "Query: How do I turn off the vibration on my Galaxy watch6?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] What should I do if lose the Buds?\n",
    "[Agent] Can you tell me the model?\n",
    "[Customer] Galaxy Buds2 Pro\n",
    "Query: What should I do if lose the Galaxy Buds2 Pro?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] I can't hear the tablet's sound well.\n",
    "[Agent] Which product are you using?\n",
    "[Customer] Galaxy Note20\n",
    "Query: How do I turn up the volume on my Galaxy Note20?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] Can I edit videos taken with the tablet?\n",
    "[Agent] What is the model?\n",
    "[Customer] Galaxy Tab A8\n",
    "Query: Can I edit videos taken with the Galaxy Tab A8?\"\"\",\n",
    " \n",
    "\"\"\"Dialogue: [Agent] Hello, my name is Lee, how can I help you today?\n",
    "[Customer] The facial recognition isn't working.\n",
    "[Agent] What is the product you are using?\n",
    "[Customer] Galaxy Note20\n",
    "Query: How do I use facial recognition on my Galaxy Note20?\"\"\"]\n",
    "\n",
    "for query in questions:\n",
    "    resultdocs = db.similarity_search_with_score(query, k=3)\n",
    "    indocs = []\n",
    "    for doc, score in resultdocs:\n",
    "        print(f\"\\n{doc}\")\n",
    "        print(f\"score:{score}\")\n",
    "        if score < 1:\n",
    "            indocs += [doc]\n",
    "    print(f\"len: {len(indocs)}\")\n",
    "    answerss = chain.run(input_documents=[], question=query)\n",
    "    print(\"\\n\\nQ:\"+query)\n",
    "    print(\"\\nA(SS):\"+answerss)\n",
    "    result = qa_chain({\"query\": query})\n",
    "    answerr = result[\"result\"]\n",
    "    print(\"A(R):\"+answerr)\n",
    "    new_record = pd.DataFrame([{'Question':query, \n",
    "                                'Answer_Similarity_Search':answerss,\n",
    "                                'Answer_Retriever':answerr,\n",
    "                                }])\n",
    "    data = pd.concat([data,new_record],ignore_index=True)\n",
    "\n",
    "    # sources = result[\"source_documents\"]\n",
    "    # for src in sources:\n",
    "    #     print(src)\n",
    "    end = time.time()\n",
    "    \n",
    "print(\"Duration: \", end - start, \"Count: \", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
