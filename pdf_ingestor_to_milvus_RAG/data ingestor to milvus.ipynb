{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from pymilvus import connections\n",
    "from pymilvus import FieldSchema\n",
    "from pymilvus import CollectionSchema\n",
    "from pymilvus import DataType\n",
    "from pymilvus import Collection\n",
    "from pymilvus import utility\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import genai.extensions.langchain\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "from genai.schemas import GenerateParams\n",
    "from genai import Credentials\n",
    "from genai import Model\n",
    "from genai import PromptPattern\n",
    "\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", None)\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", None)\n",
    "DIMENSION = os.getenv(\"DIMENSION\", None)\n",
    "COUNT = os.getenv(\"COUNT\", None)\n",
    "MAX = os.getenv(\"MAX\",None)\n",
    "MILVUS_HOST = os.getenv(\"MILVUS_HOST\", None)\n",
    "MILVUS_PORT = os.getenv(\"MILVUS_PORT\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunk_overlap = 150\n",
    "separator = \"\\n\"\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator=separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "creds = Credentials(api_key)\n",
    "params = GenerateParams(\n",
    "    decoding_method = \"greedy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(host = MILVUS_HOST, port = MILVUS_PORT)\n",
    "\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "   utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name = \"id\", dtype = DataType.INT64, description = \"Ids\", is_primary = True, auto_id = False),\n",
    "    FieldSchema(name = \"content\", dtype = DataType.VARCHAR, description = \"Content texts\", max_length = 768*8),\n",
    "    FieldSchema(name = \"embedding\", dtype = DataType.FLOAT_VECTOR, description = \"Embedding vectors\", dim = 768)\n",
    "]\n",
    "schema = CollectionSchema(fields = fields, description = \"content collection\")\n",
    "collection = Collection(name = COLLECTION_NAME, schema = schema)\n",
    "\n",
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 1024}\n",
    "}\n",
    "collection.create_index(field_name = \"embedding\", index_params = index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPDF(filename):\n",
    "    loader = PyPDFLoader(filename)\n",
    "    pages = loader.load()\n",
    "\n",
    "    len(pages)\n",
    "\n",
    "    docs = r_splitter.split_documents(pages)\n",
    "\n",
    "    print(docs[1].page_content)\n",
    "    print(docs[1].metadata)\n",
    "    len(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeToMilvus(docs):\n",
    "    start = time.time()\n",
    "    data = [[], [], []]\n",
    "    if docs:\n",
    "        for idx, text in enumerate(docs):\n",
    "            data[0].append(idx)\n",
    "            data[1].append(text.page_content)\n",
    "            if len(text.page_content) > 768:\n",
    "                tt = text.page_content[:766] + \"..\"\n",
    "                data[2].append(embeddings.embed_query(tt))\n",
    "            else:\n",
    "                data[2].append(embeddings.embed_query(text.page_content))\n",
    "\n",
    "    collection.insert(data)\n",
    "    end = time.time()\n",
    "    print(\"Duration: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for path in Path('menu/').rglob('*.pdf'):\n",
    "    print('menu/'+ path.name)\n",
    "    docs = loadPDF('menu/'+ path.name)\n",
    "    storeToMilvus(docs)\n",
    "\n",
    "# print(\"Number of entities: \", collection.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"sample.txt\", \"r\")\n",
    "questions = file.readlines()\n",
    "\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Milvus.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = Credentials(api_key,api_endpoint)\n",
    "\n",
    "params = GenerateParams(\n",
    "    decoding_method=\"greedy\",\n",
    "    max_new_tokens=300,\n",
    "    min_new_tokens=15,\n",
    "    repetition_penalty=2,\n",
    ")\n",
    "llm = LangChainInterface(model=\"meta-llama/llama-2-13b\",credentials=creds,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "for query in questions:\n",
    "    print(\"Q:\"+query)\n",
    "    resultdocs = db.similarity_search(query, k=3)\n",
    "    # for res in resultdocs:\n",
    "    #     print(res)\n",
    "    answer = chain.run(input_documents=resultdocs, question=query)\n",
    "    print(\"A:\"+answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
